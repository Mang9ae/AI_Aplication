{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwGJpsrIx8AYZp3WcZkEJ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mang9ae/AI_Aplication/blob/main/10%EC%A3%BC%EC%B0%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of8fh0SLmxYJ"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HF_TOKEN'] = \"발급 받은 토큰\""
      ],
      "metadata": {
        "id": "ciM-wNFJm1RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ],
      "metadata": {
        "id": "iMaFSRX6m3v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "#모델 ID 에 맞는 토크나이저 가져오기\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "#모델 ID 에 해당하는 model 로딩하기\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",)"
      ],
      "metadata": {
        "id": "SXOVB2wPm4GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(system_message, user_message):\n",
        "  #대화 맥락(chat history)\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"content\": user_message},\n",
        "  ]\n",
        "\n",
        "  #전달된 message 에 대해서 프롬프트 자동 생성\n",
        "  input_ids = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "  #응답 종료 기준(종료 토큰), end of turn\n",
        "  terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "  ]\n",
        "\n",
        "  #텍스트 생성을 위한 설정 및 생성\n",
        "  #max_new_tokens: 최대 생성 토큰 수\n",
        "  #temperature(sampling temperature): 낮을수록 더 결정적인 응답, 높으면 다양성 증가\n",
        "  #top_p: 확률 누적 합이 p 이하인 후보군에서 샘플링\n",
        "  outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9  )\n",
        "\n",
        "  response = outputs[0][input_ids.shape[-1]:]\n",
        "  return tokenizer.decode(response, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "4O3fp19vm7jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/jskimn/aiservice_lesson/main/003_llama3/NvidiaSmiMonitor.py\n",
        "from NvidiaSmiMonitor import NvidiaSmiMonitor\n",
        "import sys\n",
        "import time\n",
        "\n",
        "monitor = NvidiaSmiMonitor(interval=60)  # 2초마다 실행\n",
        "monitor.start()\n",
        "\n",
        "# 10초 동안 실행 후 종료\n",
        "#time.sleep(10)"
      ],
      "metadata": {
        "id": "QiXL-JDhm8A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = generate_response(system_message=\"\",\n",
        "                              user_message=\"한국어로 대답해줘. 배화여대에 대해서 말해줘\")\n",
        "print(response)\n",
        "\n",
        "\n",
        "monitor.stop()\n",
        "monitor.join()\n",
        "print(\"monitor---------종료\")"
      ],
      "metadata": {
        "id": "l3OzymXXm9-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RXyGwE54m_WI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}